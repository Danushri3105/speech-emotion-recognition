# -*- coding: utf-8 -*-
"""Speech ER

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/bdanushri/speech-er.46267f0c-4447-4d66-9e63-2b6685e4ab82.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250602/auto/storage/goog4_request%26X-Goog-Date%3D20250602T103254Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D9fd6b5403bf36e7aa5bbeae6463b84b5f90e668dac78ba024617c72d01e7c87bd816da6976298c12163037177deb3dbebf0834240152d4347da018b42bdcfb885374909ae267c59a4eab4a19ece515e3b6bbf8bd5de0ceb663ffdc2ff3ef6eb83b40425bb6320d8eb1f73ad22bfd14c69f54f84dac8d569b403bd9fd5dcb6055c0299dfa15cbc3722cfe9b725fd5a4f9ae3f24f740c0c1eca0abbd4e796d7ae5411867c11063ad4d1ff09f2a06e03abb1e7aebdc15818053f6af0738f629eebaade00d1c0841c64a6c15b87fbba6d29fda9825134245df3b37dc641290dae65f43375c54e1b7d7801abe7a503857c1eb13703ecb7c95c7c67bcdd7037c104bd1
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.
import kagglehub
ejlok1_toronto_emotional_speech_set_tess_path = kagglehub.dataset_download('ejlok1/toronto-emotional-speech-set-tess')

print('Data source import complete.')

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

#import os
#for dirname, _, filenames in os.walk('/kaggle/input'):
  #  for filename in filenames:
   #     print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

import pandas as pd
import numpy as np
import os
import librosa
import librosa.display
import seaborn as sns
import matplotlib.pyplot as plt
from IPython.display import Audio
import warnings
warnings.filterwarnings("ignore")

paths=[]
labels=[]
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        paths.append(os.path.join(dirname,filename))
        label = filename.split('_')[-1]
        label = label.split('.')[0]
        labels.append(label.lower())
print('Dataset is loaded')

df = pd.DataFrame({'speech':paths,'label':labels})

print(df['label'].value_counts())

df['label'] = df['label'].astype('category')

plt.figure(figsize=(10, 6))
sns.countplot(x=df['label'], order=df['label'].value_counts().index)
plt.xticks(rotation=45)
plt.title("Label Distribution")
plt.show()

import librosa
import librosa.display
import matplotlib.pyplot as plt
import numpy as np

# Function to plot waveform
def waveplot(data, sr, emotion):
    plt.figure(figsize=(10, 4))
    plt.title(f"Waveform: {emotion}", size=20)
    librosa.display.waveshow(data, sr=sr)
    plt.xlabel("Time (s)")
    plt.ylabel("Amplitude")
    plt.show()

# Function to plot spectrogram
def spectrogram(data, sr, emotion):
    plt.figure(figsize=(10, 4))
    plt.title(f"Spectrogram: {emotion}", size=20)
    # Compute Mel spectrogram
    S = librosa.feature.melspectrogram(y=data, sr=sr, n_mels=128, fmax=8000)
    S_dB = librosa.power_to_db(S, ref=np.max)  # Convert to dB scale
    librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel', cmap='viridis')
    plt.colorbar(format='%+2.0f dB')
    plt.xlabel("Time (s)")
    plt.ylabel("Frequency (Hz)")
    plt.tight_layout()
    plt.show()

# Example Usage
emotion = 'fear'
path = df['speech'][df['label'] == emotion].iloc[0]  # Replace with actual DataFrame logic
data, sampling_rate = librosa.load(path, sr=None)

waveplot(data, sampling_rate, emotion)
spectrogram(data, sampling_rate, emotion)
Audio(path)

emotion = 'angry'
path = np.array(df['speech'][df['label'] == emotion])[2]  # Replace with actual DataFrame logic
data, sampling_rate = librosa.load(path, sr=None)

waveplot(data, sampling_rate, emotion)
spectrogram(data, sampling_rate, emotion)
Audio(path)

emotion = 'disgust'
path = np.array(df['speech'][df['label'] == emotion])[2]  # Replace with actual DataFrame logic
data, sampling_rate = librosa.load(path, sr=None)

waveplot(data, sampling_rate, emotion)
spectrogram(data, sampling_rate, emotion)
Audio(path)

emotion = 'neutral'
path = np.array(df['speech'][df['label'] == emotion])[2]  # Replace with actual DataFrame logic
data, sampling_rate = librosa.load(path, sr=None)

waveplot(data, sampling_rate, emotion)
spectrogram(data, sampling_rate, emotion)
Audio(path)

emotion = 'sad'
path = np.array(df['speech'][df['label'] == emotion])[2]  # Replace with actual DataFrame logic
data, sampling_rate = librosa.load(path, sr=None)

waveplot(data, sampling_rate, emotion)
spectrogram(data, sampling_rate, emotion)
Audio(path)

emotion = 'ps'
path = np.array(df['speech'][df['label'] == emotion])[2]  # Replace with actual DataFrame logic
data, sampling_rate = librosa.load(path, sr=None)

waveplot(data, sampling_rate, emotion)
spectrogram(data, sampling_rate, emotion)
Audio(path)

emotion = 'happy'
path = np.array(df['speech'][df['label'] == emotion])[2]  # Replace with actual DataFrame logic
data, sampling_rate = librosa.load(path, sr=None)

waveplot(data, sampling_rate, emotion)
spectrogram(data, sampling_rate, emotion)
Audio(path)

def extract_mfcc(filename):
    y,sr = librosa.load(filename, duration=3, offset=0.5)
    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T,axis=0)
    return mfcc

extract_mfcc(df['speech'][0])

x_mfcc = df['speech'].apply(lambda x:extract_mfcc(x))
x_mfcc

x_mfcc

x = [x for x in x_mfcc]
x = np.array(x)
x.shape

##input split
x = np.expand_dims(x,-1)
x.shape

from sklearn.preprocessing import OneHotEncoder
enc = OneHotEncoder()
y = enc.fit_transform(df[['label']])
y = y if isinstance(y, np.ndarray) else y.toarray()

y.shape

"""**Create the LSTM model**"""

from keras.models import Sequential
from keras.layers import Dense, LSTM, Dropout

model = Sequential([
    LSTM(123, return_sequences=False, input_shape=(40,1)),
    Dense(64, activation='relu'),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dropout(0.2),
    Dense(7, activation='softmax')
])

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()

#train the model
history = model.fit(x,y, validation_split=0.2, epochs=100, batch_size=512, shuffle=True)

epochs = list(range(100))
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

plt.plot(epochs, acc, label='train accuracy')
plt.plot(epochs, val_acc, label='train accuracy')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.legend()
plt.show()

loss = history.history['loss']
val_loss = history.history['val_loss']

plt.plot(epochs, loss, label='train loss')
plt.plot(epochs, val_loss, label='train loss')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.legend()
plt.show()